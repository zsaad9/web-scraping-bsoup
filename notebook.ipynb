{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "id": "uqyJrrJi0Cuz",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 1. Tools for text processing\n",
    "<p><img style=\"float: right ; margin: 5px 20px 5px 10px; width: 45%\" src=\"https://images3.penguinrandomhouse.com/cover/9780147514011\"> </p>\n",
    "<p>In this project, we aim to analyze the most frequent words in Louisa May Alcott's classic novel, \"Little Women,\" and examine how often they occur throughout the text. To achieve this, we'll utilize various Python libraries and tools to scrape the novel from Project Gutenberg, a platform providing free access to a vast collection of ebooks, and extract relevant text data using BeautifulSoup. By employing natural language processing techniques and tools such as NLTK and Counter, we'll delve into the distribution of words within the novel, uncovering insights into its linguistic makeup.\n",
    "\n",
    "Credit goes to Project Gutenberg for generously providing the free ebook and HTML data, enabling us to explore and analyze this literary work in a data-driven manner. Through this project, we'll demonstrate a data science pipeline applicable not only to \"Little Women\" but also to other novels available on Project Gutenberg, showcasing the power of natural language processing in uncovering patterns and insights within unstructured text data.</p>\n",
    "\n",
    "Feel free to get in touch with your comments and feedback.\n",
    "\n",
    "Email: zaidsaad99@gmail.com\n",
    "\n",
    "Github: https://github.com/zsaad9\n",
    "\n",
    "LinkedIn: https://www.linkedin.com/in/zaidbsaad/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "id": "EVVF9tYA0Cu7",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Importing requests, BeautifulSoup, nltk, and Counter\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "10"
    },
    "deletable": false,
    "editable": false,
    "id": "U3Cia7du0Cu_",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 2. Request Little Women\n",
    "<p>To analyze Little Women, we need to get the contents of the book from <em>somewhere</em>. Luckily, the text is freely available online at Project Gutenberg as an HTML file: https://www.gutenberg.org/cache/epub/37106/pg37106-images.html .</p>\n",
    "<p>To fetch the HTML file with Little Women we're going to use the <code>request</code> package to make a <code>GET</code> request for the website, which means we're <em>getting</em> data from it. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "id": "0yhJ3vcJ0CvA",
    "outputId": "6000703c-643b-4963-97a1-80c922a74463",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"><style>\n",
      "#pg-header div, #pg-footer div {\n",
      "    all: initial;\n",
      "    display: block;\n",
      "    margin-top: 1em;\n",
      "    margin-bottom: 1em;\n",
      "    margin-left: 2em;\n",
      "}\n",
      "#pg-footer div.agate {\n",
      "    font-size: 90%;\n",
      "    margin-top: 0;\n",
      "    margin-bottom: 0;\n",
      "    text-align: center;\n",
      "}\n",
      "#pg-footer li {\n",
      "    all: initial;\n",
      "    display: block;\n",
      "    margin-top: 1em;\n",
      "    margin-bottom: 1em;\n",
      "    text-indent: -0.6em;\n",
      "}\n",
      "#pg-footer div.secthead {\n",
      "    font-size: 110%;\n",
      "    font-weight: bold;\n",
      "}\n",
      "#pg-footer #project-gutenberg-license {\n",
      "    font-size: 110%;\n",
      "    margin-top: 0;\n",
      "    margin-bottom: 0;\n",
      "    text-align: center;\n",
      "}\n",
      "#pg-header-heading {\n",
      "    all: inherit;\n",
      "    text-align: center;\n",
      "    font-size: 120%;\n",
      "    font-weight:bold;\n",
      "}\n",
      "#pg-footer-heading {\n",
      "    all: inherit;\n",
      "    text-align: center;\n",
      "    font-size: 120%;\n",
      "    font-weight: normal;\n",
      "    margin-top: 0;\n",
      "    margin-bottom: 0;\n",
      "}\n",
      "#pg-header #pg-machine-header p {\n",
      "    text-indent: -4em;\n",
      "    margin-left: 4em;\n",
      "    margin-top: 1em;\n",
      "    margin-bottom: 0;\n",
      "    font-size: medium\n",
      "}\n",
      "#pg-header #pg-header-authlist {\n",
      "    all: initial;\n",
      "    margin-top: 0;\n",
      "    margin-bottom: 0;\n",
      "}\n",
      "#pg-header #pg-machine-header strong {\n",
      "    font-weight: normal;\n",
      "}\n",
      "#pg-header #pg-start-separator, #pg-footer #pg-end-separator {\n",
      "    margin-bottom: 3em;\n",
      "    margin-left: 0;\n",
      "    margin-right: auto;\n",
      "    margin-top: 2em;\n",
      "    text-align: center\n",
      "}\n",
      "\n",
      "    .xhtml_center {text-align: center; display: block;}\n",
      "    .xhtml_center table {\n",
      "        display: table;\n",
      "        text-align: left;\n",
      "        margin-left: auto;\n",
      "        margin-right: auto;\n",
      "        }</style><title>The Project Gutenberg eBook of Little Women, by Louisa M. Alcott</title>\n",
      "<link href=\"images/cover.png\" rel=\"icon\" type=\"image/x-cover\" id=\"id-3870157190676821730\">\n",
      "<style>body {\n",
      "    margin-left: 10%;\n",
      "    margin-right: 10%\n",
      "    }\n",
      "h1 {\n",
      "    margin-top: 7%;\n",
      "    text-indent: 0%;\n",
      "    text-align: center;\n",
      "    clear: bot\n"
     ]
    }
   ],
   "source": [
    "# Getting the Little Women HTML\n",
    "r = requests.get(\"https://www.gutenberg.org/cache/epub/37106/pg37106-images.html\")\n",
    "\n",
    "# Setting the correct text encoding of the HTML page\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "# Extracting the HTML from the request object\n",
    "html = r.text\n",
    "\n",
    "# Printing the first 2000 characters in html\n",
    "print(html[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "17"
    },
    "deletable": false,
    "editable": false,
    "id": "CbXrLzPW0CvD",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. Getting the text from the HTML\n",
    "<p>This HTML is not quite what we want. However, it does <em>contain</em> what we want: the text of <em>Little Women</em>. What we need to do now is <em>wrangle</em> this HTML to extract the text of the novel. For this we'll use the package <code>BeautifulSoup</code>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "id": "-ITO9olx0CvF",
    "outputId": "619f6572-da44-4446-dfff-6f22c791ed2d",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rong place with\n",
      "a croak or a quaver that spoilt the most pensive tune. They had\n",
      "always done this from the time they could lisp\n",
      "\"Crinkle, crinkle, 'ittle 'tar,\"\n",
      "\n",
      "and it had become a household custom, for the mother was a born\n",
      "singer. The first sound in the morning was her voice, as she went\n",
      "about the house singing like a lark; and the last sound at night was\n",
      "the same cheery sound, for the girls never grew too old for that\n",
      "familiar lullaby.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "II. A Merry Christmas.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "II.\n",
      "A MERRY CHRISTMAS.\n",
      "Jo was the first to wake in the gray dawn of Christmas morning.\n",
      "No stockings hung at the fireplace, and for a moment she felt as\n",
      "much disappointed as she did long ago, when her little sock fell down\n",
      "because it was so crammed with goodies. Then she remembered her\n",
      "mother's promise, and, slipping her hand under her pillow, drew out\n",
      "a little crimson-covered book. She knew it very well, for it was that\n",
      "beautiful old story of the best life ever lived, and Jo felt that it was\n",
      "a true guide-book for any pilgrim going the long journey. She woke\n",
      "Meg with a \"Merry Christmas,\" and bade her see what was under\n",
      "her pillow. A green-covered book appeared, with the same picture\n",
      "inside, and a few words written by their mother, which made their\n",
      "one present very precious in their eyes. Presently Beth and Amy\n",
      "woke, to rummage and find their little books also,—one dove-colored,\n",
      "the other blue; and all sat looking at and talking about them, while\n",
      "the east grew rosy with the coming day.\n",
      "In spite of her small vanities, Margaret had a sweet and pious\n",
      "nature, which unconsciously influenced her sisters, especially Jo, who\n",
      "loved her very tenderly, and obeyed her because her advice was so\n",
      "gently given.\n",
      "\"Girls,\" said Meg seriously, looking from the tumbled head beside\n",
      "her to the two little night-capped ones in the room beyond,\n",
      "\"mother wants us to read and love and mind these books, and we\n",
      "must begin at once. We used to be faithful about it; but since\n",
      "father went away, and all this w\n"
     ]
    }
   ],
   "source": [
    "# Creating a BeautifulSoup object from the HTML\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Getting the text out of the soup\n",
    "text = text = soup.get_text()\n",
    "\n",
    "# Printing out text between characters 32000 and 34000\n",
    "print(text[32000:34000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "24"
    },
    "deletable": false,
    "editable": false,
    "id": "Joj-mNaw0CvG",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. Extracting the words\n",
    "<p>We now have the text of the novel! There is some unwanted stuff at the start and some unwanted stuff at the end. We could remove it, but this content is so much smaller in amount than the text of Little Women that, to a first approximation, it is okay to leave it in.</p>\n",
    "<p>Now that we have the text of interest, it's time to count how many times each word appears, and for this we'll use <code>nltk</code> – the Natural Language Toolkit. We'll start by tokenizing the text, that is, remove everything that isn't a word (whitespace, punctuation, etc.) and then split the text into a list of words.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "24"
    },
    "id": "iyMfFeOi0Cvg",
    "outputId": "3b781322-9580-470f-8967-324c89be87ed",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Little', 'Women', 'by']\n"
     ]
    }
   ],
   "source": [
    "# Creating a tokenizer\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Tokenizing the text\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "# Printing out the first 8 words / tokens\n",
    "print(tokens[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "31"
    },
    "deletable": false,
    "editable": false,
    "id": "Ayp3hkee0Cvh",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. Making the words lowercase\n",
    "<p>OK! We're nearly there. Note that in the above 'Little' has a capital 'L' and that in other places it may not, but both 'Little' and 'little' should be counted as the same word. For this reason, we should build a list of all words in <em>Little Women</em> in which all capital letters have been made lower case.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "id": "6nM1FjmO0Cvh",
    "outputId": "32753b61-27f9-4510-99cf-4385c6ec87f7",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'little', 'women', 'by']\n"
     ]
    }
   ],
   "source": [
    "# Create a list called words containing all tokens transformed to lower-case\n",
    "words = [word.lower() for word in tokens]\n",
    "\n",
    "# Printing out the first 8 words / tokens\n",
    "print(words[:8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "38"
    },
    "deletable": false,
    "editable": false,
    "id": "JEGe7crP0Cvi",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Loading in the stop words\n",
    "<p>It is common practice to remove words that appear a lot in the English language such as 'the', 'of' and 'a' because they're not so interesting. Such words are known as <em>stop words</em>. The package <code>nltk</code> includes a good list of stop words in English that we can use.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "id": "xsoxZ10r0Cvj",
    "outputId": "196477a3-c1ec-4850-caf6-4d525e806e95",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Getting the English stop words from nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "print(sw[:8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "45"
    },
    "deletable": false,
    "editable": false,
    "id": "P7iy4LLT0Cvj",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 7. Removing stop words in Little Women\n",
    "<p>We now want to create a new list with all <code>words</code> in the novel, except those that are stop words (that is, those words listed in <code>sw</code>).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "id": "_g-dmsva0Cvk",
    "outputId": "04a38ac1-0ac4-4167-c803-4cac80a853a8",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'little', 'women']\n"
     ]
    }
   ],
   "source": [
    "# Creating a list words_ns containing all words that are in words but not in sw\n",
    "words_ns = [word for word in words if word not in sw]\n",
    "\n",
    "# Printing the first 5 words_ns to check that stop words are gone\n",
    "print(words_ns[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "52"
    },
    "deletable": false,
    "editable": false,
    "id": "CUFF5THt0Cvk",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 8. We have the answer\n",
    "<p>Our original question was:</p>\n",
    "<blockquote>\n",
    "  <p>What are the most frequent words in Louisa May Alcott's classic novel, \"Little Women\" and how often do they occur?</p>\n",
    "</blockquote>\n",
    "<p>Let's answer this question using the <code>Counter</code> class we imported.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "id": "Jml1tgWi0Cvl",
    "outputId": "1c4f96c5-5a6a-4c9c-edc3-8a3e603c4dc3",
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jo', 1406), ('one', 900), ('said', 839), ('little', 773), ('meg', 704), ('amy', 669), ('laurie', 610), ('like', 604), ('beth', 494), ('good', 481)]\n"
     ]
    }
   ],
   "source": [
    "# Initializing a Counter object from our processed list of words\n",
    "count = Counter(words_ns)\n",
    "# Storing 10 most common words and their counts as top_ten\n",
    "top_ten = count.most_common(10)\n",
    "\n",
    "# Print the top ten words and their counts\n",
    "print(top_ten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "59"
    },
    "deletable": false,
    "editable": false,
    "id": "dEJVl59A0Cvm",
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 9. The most common word\n",
    "<p>Using our variable <code>top_ten</code>, we now have an answer to our original question.</p>\n",
    "<p>The natural language processing skills we used in this notebook are also applicable to much of the vast proportion of the world's data that is unstructured data and includes a great deal of text. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7IAlRTH0Cvm",
    "outputId": "afea9abc-5288-408e-a296-e4ae16ed9cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('jo', 1406)]\n"
     ]
    }
   ],
   "source": [
    "# What's the most common word in Little Women?\n",
    "print(count.most_common(1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
